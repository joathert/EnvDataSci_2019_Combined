{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Introduction\n",
    "\n",
    "In this session we will outline a basic environmental data work-flow. Our goal \n",
    "is to highlight common data tasks, and typical ways to solve\n",
    "them in R. \n",
    "\n",
    "\n",
    "When working with environmental data, there are usually a few steps\n",
    "that come up each time. These are:\n",
    "  \n",
    "* **reading**. Typically data is read from text files, but can also come from the\n",
    "internet or in other format \n",
    "* **processing**. The data we read is usually a little \n",
    "untidy , for example we may need to subset to correct dates.\n",
    "* **plotting**. Plotting data is always worth doing as early as\n",
    "possible. Use histograms or simple line plots as your first steps\n",
    "in visualising data.  \n",
    "\n",
    "To do these efficiently in R is mainly about learning which\n",
    "functions to use, and how to apply these functions. \n",
    "\n",
    "In this notebook we will work through each step in turn with \n",
    "example data. We will once again work with data downloaded from\n",
    "SMARTSMEAR, in this case we will use flux data measured using the\n",
    "eddy co-variance technique at SMEARII research station. We will use Temperature \n",
    "which is measured at 16.8m Height, Gross Primary Production (GPP) which \n",
    "is derived from measurements of CO2 exchange, and Evapotranspiration (ET) \n",
    "which is derived from measurements of H2O exchange. \n",
    "\n",
    "Before we start there is one other thing we should mention.In this\n",
    "session we will assume that terms like *function*, *argument* are\n",
    "familiar to you. If they are not then go back to\n",
    "R1-introduction.ipynb, and check the definition. If you cannot find\n",
    "the definition in there then complain to your instructors to update\n",
    "the intro! Alright, let's get started.\n",
    "\n",
    " \n",
    "# 1. Reading\n",
    "\n",
    "Our first task is to read in our GPP, ET and temperature data. Reading data \n",
    "takes data from storage (typically your computer's hard disk) and places it\n",
    "somewhere (in RAM) that is can be operated on by R.  We have already\n",
    "downloaded our data as two seperate text files from SMARTSMEAR, and\n",
    "stored these files in the */data* directory (folder) on github:\n",
    "https://github.com/OptPhotLab/EnvDataSciNotebooks/tree/master/data\n",
    "(You can inspect the data files by clicking the github link, but opening\n",
    "the individual files on github could slow your computer down!)\n",
    "\n",
    "There are a few different functions for reading data in R, these include:\n",
    "\n",
    "* read.csv\n",
    "* read.table\n",
    "* read.delim \n",
    "* read.csv2 \n",
    "\n",
    "We can use **help** to inspect these functions, see what arguments they\n",
    "have, and how to set these arguments so that you can read your\n",
    "data/file in a proper way. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(read.csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use *read.csv* to read in our GPP dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpp<-read.csv('../data/gppsmeardata_20160101120000.csv',header = T,sep = ',',dec='.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The double dots **..** in the path tell R to go up a level in the directory (folder) hierarchy. The full path (location) of the ET data is:\n",
    "\n",
    "*../data/ET smeardata_20160101120000.csv*\n",
    "\n",
    "go ahead and read the ET data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the output data ET\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is as simple as that! \n",
    "\n",
    "We have read our data into the memory, the next step is\n",
    "processing. But just before we move on we can use the *head* function to inspect \n",
    "the first few lines of our data object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can you also remember how to check the type of our objects?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Processing\n",
    "\n",
    "Before we can make any graphs or perform any stats we usually have to tidy our data\n",
    "and there are a bunch of techniques in R that can help out with this. Let's \n",
    "check out a few of them that make life easier.\n",
    "\n",
    "## 2.1. Combining \n",
    "\n",
    "We read in *two* different data files which have same first six columns. We can make life easier by combining these into a single dataframe using *merge()* function. \n",
    "\n",
    "Use the *by* argument to set which variables are shared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpp.ET<-merge(gpp,ET,by=c(\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\", \"Second\"),all = T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use *head* to check the combination worked:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's read the third file: temperature into R.\n",
    "\n",
    "*'../data/T168_20160101120000.csv'* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the output data temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will combine temperature (temp) data with gpp and ET. \n",
    "\n",
    "Try yourself here and name the combined file as *merge.all*:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, merge() can be only used to combine two dataframe into one file. Can we combine multiple files into one using one function at one time? The answer is Yes. \n",
    "\n",
    "*Reduce()* function is one of the solutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note x or y is index, they can also be anything else, such as m and n.\n",
    "reduce.all<-\n",
    "  Reduce(function(x,y) merge(x,y,by=c(\"Year\",\"Month\",\"Day\",\n",
    "                                      \"Hour\",\"Minute\",\"Second\"),all = T),\n",
    "         list(gpp,ET,temp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the str of *reduce.all* that should be exactly same with *merge.all* \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Rename the column names\n",
    "\n",
    "We can check the colunm names using *names(data)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(reduce.all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also use *names(data)* to change the column names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(reduce.all)<-c(\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\",\"Second\",\n",
    "                     \"HYY_EDDY233.GPP\",\"HYY_EDDY233.ET_gapf\",\"HYY_META.T168\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But usually we only want to change few column names:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(reduce.all)[8]<-'ET'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(reduce.all)[c(7,9)]<-c('GPP','T168')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the updated column names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Subsetting\n",
    "\n",
    "### Method 1\n",
    "\n",
    "Often we download much more data than we need. Subsetting using the *subset* function\n",
    "is a useway to restrict our datasets to the bits we are actually interested in.\n",
    "\n",
    "*subset* accepts column names as a second argument. You can use subset to \n",
    "extract data for the month of September from *reduce.all* like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce.all.sep <- subset(reduce.all, Month==9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you create a new dataframe containing data measured at midday (when hour is between 10 and 15 o'clock) only? \n",
    "\n",
    "Name this dataframe *reduce.all.midday*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use *head* to check the dates are correct:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2.\n",
    "\n",
    "We can also subset the data inside the dataframe. \n",
    "\n",
    "*data[row.index,column.index]*\n",
    "\n",
    "*Example 1*, we want to select first 7 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam1<-reduce.all[c(1:7),]\n",
    "exam1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example 2*, we want to select data *reduce.all* when row numbers are 2, 50, and 100:102 and keep first 7 columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam2<-reduce.all[c(2,50,100:102),1:7]\n",
    "exam2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also select data by specific conditions. \n",
    "\n",
    "*Example 3*, We want to select the rows when the Hour is between 10 and 15 o'clock (midday data) and keep all the columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce.all.midday<-reduce.all[reduce.all$Hour>10&reduce.all$Hour<15,]\n",
    "head(reduce.all.midday)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 reordering\n",
    "\n",
    "Did you notice something odd? The days are not in ascending order. We can sort this out using *order()* function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce.all.midday <- \n",
    "  reduce.all.midday[order(reduce.all.midday$Year,reduce.all.midday$Month,reduce.all.midday$Day), ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if this has worked out as expected:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a single dataframe with data at our desired midday time-step we \n",
    "can start with our visualisations.\n",
    "\n",
    "# 3. Plotting using basic plot() function in r\n",
    "\n",
    "## 3.1 Line plot\n",
    "\n",
    "The simplest plot of them all is the dot (or line) plot. The *plot* command is your friend here!\n",
    "\n",
    "Let's see what our GPP data looks like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(reduce.all.midday$GPP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.2 Scatter plot\n",
    "\n",
    "We can also use *plot* to plot the relationship between variables by\n",
    "making scatter plots. Use the **~** operator to achieve this\n",
    "e.g. *plot(A~B,data=data.AB)*, where *A* and *B* are our\n",
    "variables and *data.AB* is our dataframe that contains our variables.\n",
    "\n",
    "Try to make a scatter plot between GPP and ET for our midday data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(GPP~ET,data = reduce.all.midday)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.3 histogram\n",
    "\n",
    "Checking the distribution of your data is usually a very good idea! \n",
    "**hist** is used to draw histograms. How is our midday GPP distributed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(reduce.all.midday$GPP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Panels\n",
    "\n",
    "Subplots (multiple plots in the same window) in R are achieved with\n",
    "the panels or *par* command. Specify the number of rows and\n",
    "columns as a two element vector and pass it using the *mfrow* key word\n",
    "as an argument to *par* e.g. par(mfrow =c(num.row,num.col)), then use\n",
    "repeated calls to *plot* in the usual way.\n",
    "\n",
    "Can you complete the box below to draw ET and GPP in the same window\n",
    "but as separate subplots?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first swap num.row and num.col for integers *par(mfrow =c(num.row,num.col))*\n",
    "# then call plot() for each plot instance\n",
    "par(mfrow=c(2,1))\n",
    "plot(reduce.all.midday$GPP)\n",
    "plot(reduce.all.midday$T168)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Plotting using ggplot() function in ggplot2 packages\n",
    "\n",
    "ggplot(data,aes(x=A,y=B))+\n",
    "  geom_point()+\n",
    "  geom_line()\n",
    "  \n",
    "\n",
    "Let's plot the scatter plot of GPP vs. ET. We can also assign the plot to a variable name, and later using ggsave() to save your graph. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "p<-\n",
    "  ggplot(reduce.all.midday,aes(x=ET,y=GPP))+\n",
    "    geom_point()\n",
    "p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add a regression line to the scatter plot and name the plot as *p2*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2<-p+geom_smooth(method = 'lm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
